### 见PDF注释

### 见PDF注释

### LLaMA大语言模型

参数量级很大，在许多基准测试中都优于GPT-3

模型参数量级的积累，或者训练数据的增加，哪个对性能提升帮助更大？

大家好像有一个共识，就是：**模型参数量级的增加就会带来同样的性能提升。**

但是事实确实如此吗？

根据**缩放定律**：

当我们给定特定的计算成本预算的前提下，语言模型的最佳性能不仅仅可以通过设计较大的模型搭配小一点的数据集得到，也可以通过设计较小的模型配合大量的数据集得到。

那么，**相似成本训练 LLM，是大 LLM 配小数据训练，还是小 LLM** **配大数据训练更好？**

根据**LLaMA: Open and Efficient Foundation Language Models**这篇论文得出，作者认为，大部分人是用已经训练好的LLM进行推理的，所以，我们首选的模型应该不是训练最快的，而是推理最快的LLM。

所以，对于用已经训练好的LLM来说，小LLM配大数据训练更好，因为小LLM推理更友好。

### 参数规模的选择

### 千亿参数级别的模型

百亿参数是模型具备涌现能力的门槛，千亿参数的模型具备较好的涌现能力,当模型参数量增长超过一定阈值时，模型能力表现出跃迁式的提升，表现出来语言理解能力、生成能力、逻辑推理能力等能力的显著提升，

DeepMind 的研究表明，如果把一个大模型训练充分，需要把每个参数量训练 20 个 Token。

### API接口的选择

在选择大型模型的API接口时，应该考虑以下几个关键因素：**功能和任务需求**，**性能和准确度**

，**支持的语言和功能**，**成本和价格**，**可扩展性**

，**技术支持和文档**



### 低质量信息的处理

**数据清洗**

**停用词过滤和词频处理**：同时可以利用词频和逆文档频率（TF-IDF）来识别常见、过于普遍的词语，对其进行过滤或赋予适当的权重。

**噪音识别**：将文本分为“高质量”、“噪音”和“低质量”三类。利用训练好的模型对数据进行分类，**挑选出高质量数据**。

**文本聚类**：将相似的文本数据分到一组

**主题建模**：通过主题建模技术(LDA)寻找数据中的主题结构，**只保留与关键主题相关的内容**。

**人工审核**

### openText见PDF注释

### Wiki

### BigQuery

BigQuery提供了查询数据、管理数据、加载和导出数据、权限管理功能。

可以通过API将数据加载到BigQuery中，或者将查询结果导出到其他存储系统中。

除此之外，可以使用BigQueryML，该服务允许用户直接在BigQuery中运行模型，而无需移动数据。

### The Pile

这个数据集旨在成为用于预训练大型多模态模型的资源。

和其他大模型的训练一样

**数据清洗与预处理**

.

..

...

....

### 代码库

这些代码库可以用来加载预训练模型

同时也提供了微调预训练模型的工具，使用预训练模型的参数作为起点，可以在提高模型的性能。

也提供了用于在生产环境中部署模型的工具和方法。

### ColossalAI

DeepSpeed与pytorch更友好，



与DeepSpeed-HE相比，ColossalAI在拥有相同时间预算的情况可以训练更大的模型，或者以十分之一的训练成本训练相似大小的模型。







-----------------------------------------------------------------------------------------------------------------------------

训练语料的处理非常重要，直接影响到后面模型的发挥。幻觉现象的发生，回答出现重复等现象的发生。

在处理语料的时候，（图片，我们只弄了多少）......对于重复数据的清理非常必要。但是如果清理掉了正确的数据会导致模型出现错误回答。所以，在清理重复之前，需要对初版的模型使用FacTool进行数据评测，然后再次处理语料，重复训练。3



1. 对于数据去重：使用脚本代码设置正则表达式对数据进行过滤，筛选高质量的数据源，规范化文本、去除HTML和标记，过滤停用词和噪声词，处理拼写错误、清除敏感信息。

2. 使用ai辅助进行数据清理，或者使用[贝叶斯分类算法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/26262151)，也可以可以单独训练一个过滤模型，用于识别有害内容。

3. 再次人工审查

   参考于[数据清洗：大模型训练前的热身 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/663238860)

   对于刚刚提到到的贝叶斯分类算法，当这个算法运用到训练集以清理数据时，可能导致如下问题：零概率问题，就是在计算实例的概率时，如果某个量x，在观察样本库（训练集）中没有出现过，会导致整个实例的概率结果是0。为了解决这个问题，在算法中引入加法平滑方法，对于分类算法的计算公式的分母加上取值范围的大小，在分子加1.

   平滑的目的也是正则化的目的之一：它可以令w的任何一个分量相比较于剩余分量变化程度保持一致，不至于出现变化特别明显的分量。直接的作用就是防止模型“**过拟合**”，提高了模型的泛化性能。（减少模型出现“幻觉”的可能性）
